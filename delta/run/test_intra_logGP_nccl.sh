#!/bin/bash

# ---[ Script Setup ]---

set -e

# module load mpich

module load cuda
module load openmpi

export MPI_HOME=/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/openmpi-4.1.6-lranp74
export CUDA_HOME=/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/cuda-11.8.0-vfixfmc

export LD_LIBRARY_PATH="${MPI_HOME}/lib:${CUDA_HOME}/lib64:$LD_LIBRARY_PATH"
export PATH="${MPI_HOME}/bin:${CUDA_HOME}/bin:$PATH"
export C_INCLUDE_PATH="${MPI_HOME}/include:${CUDA_HOME}/include:$C_INCLUDE_PATH"


# for the shared library generated by myself
export libnccl_HOME="/u/ldai1/ccl-build/netgauge/libnccl"

export LD_LIBRARY_PATH="${libnccl_HOME}:$LD_LIBRARY_PATH"
export C_INCLUDE_PATH="${libnccl_HOME}:$C_INCLUDE_PATH"
export CPLUS_INCLUDE_PATH="${libnccl_HOME}:$CPLUS_INCLUDE_PATH"

export NCCL_HOME=/u/ldai1/ccl-build/nccl/build
export C_INCLUDE_PATH="${NCCL_HOME}/include:$C_INCLUDE_PATH"
export CPLUS_INCLUDE_PATH="${NCCL_HOME}/include:$CPLUS_INCLUDE_PATH"
export LD_LIBRARY_PATH="${NCCL_HOME}/lib:$LD_LIBRARY_PATH"

export NCCL_DEBUG=TRACE

export NCCL_MIN_NCHANNELS=1
export NCCL_MAX_NCHANNELS=1

# echo $MALLOC_CHECK_

# for the shared library generated by myself

ldd ${libnccl_HOME}/libMyNcclCode.so

# export MALLOC_CHECK_=2
# echo $MALLOC_CHECK_

export NETGAUGE_HOME="/u/ldai1/ccl-build/netgauge"

echo "mpirun -np 2 --map-by ppr:2:node ${NETGAUGE_HOME}/netgauge -m mpi -x loggp -o ng_logGP_intranode"

# dool --time --mem --cpu --net -N ib0,ens786f1,lo,total 1 > /home/liuyao/sbatch_sh/netgauge/run/output/CPU.csv  &
#         nvidia-smi --query-gpu=name,timestamp,uuid,utilization.gpu,memory.total,utilization.memory,power.draw --format=csv -l 1 > /home/liuyao/sbatch_sh/netgauge/run/output/GPU.csv &
#         sh rtop.sh -d ib0 > /home/liuyao/sbatch_sh/netgauge/run/output/RTOP.csv  &

mpirun -np 2 --map-by ppr:2:node ${NETGAUGE_HOME}/netgauge -m mpi -x loggp -o ng_logGP_intranode -s 1-134217728 > /u/ldai1/ccl-build/netgauge-test/delta/run/output/ng_logGP_intranode.log



